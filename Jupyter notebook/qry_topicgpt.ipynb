{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2a629c7",
   "metadata": {},
   "source": [
    "# TopicGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22694b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qry1(document: str) -> str:\n",
    "    \"\"\"\n",
    "    This function generates a query to identify generalizable topics from a document based on a given topic hierarchy.\n",
    "    \n",
    "    Args:\n",
    "    document (str): The text of the document to analyze for topics.\n",
    "    \n",
    "    Returns:\n",
    "    str: A formatted query string that includes the document and instructions for identifying topics.\n",
    "    \"\"\"\n",
    "    query_template = f\"\"\"\n",
    "    You will receive a document and a set of top-level topics from a topic hierarchy. Your task is to identify generalizable topics\n",
    "    within the document that can act as top-level topics in the hierarchy. If any relevant topics are missing from the provided set,\n",
    "    please add them. Otherwise, output the existing top-level topics as identified in the document.\n",
    "    [Top-level topics]\n",
    "    [1] World news\n",
    "    [1] Weather\n",
    "    [1] Estonian local news\n",
    "\n",
    "    [Examples]\n",
    "    Example 1: Adding \"[1] Estonian local news\"\n",
    "    Document:\n",
    "    Osaühisus „Mootor“ teatas teedeministeeriumile, et täistuisanud teede tõttu on katkestatud ühendus järgmiste liinide vahel:\\n\\n- Tallinn—Märjamaa\\n- Tallinn—Loksa—Viinistu\\n- Tallinn—Tsitri—Leesi\\n\\nSõidugraafikute täitmine oli seetõttu ajutiselt wõimatu\n",
    "    Your response:\n",
    "    [1] Estonian local news: Mentsions local transportation disruptions due to weather conditions.\n",
    "    Example 2: Duplicate \"[1] Weather\", returning the existing topic\n",
    "    Document:\n",
    "    Eile hommikpoolsel ööl sadas kogu EeStis lund. Madalrõhkkond on lõuna ja kagu poole liikunud. Teine madalrõhkkond asub Põhja…b metobs.: merel paiguti kõva, maal keskmise kiirusega põhjakaarte tuuled. Pilvine. Paiguti lumesajud. Temperatuur madalam.\n",
    "    Your response:\n",
    "    [1] Weather: Mentions atmospheric conditions, precipitation, and temperature variations.\n",
    "    [Instructions]\n",
    "    Step 1: Determine topics mentioned in the document.\n",
    "    - The topic labels must be as GENERALIZABLE as possible. They must not be document-specific.\n",
    "    - The topics must reflect a SINGLE topic instead of a combination of topics.\n",
    "    - The new topics must have a level number, a short general label, and a topic description.\n",
    "    - The topics must be broad enough to accommodate future subtopics.\n",
    "    Step 2: Perform ONE of the following operations:\n",
    "    1. If there are already duplicates or relevant topics in the hierarchy, output those topics and stop here.\n",
    "    2. If the document contains no topic, return \"None\".\n",
    "    3. Otherwise, add your topic as a top-level topic. Stop here and output the added topic(s). DO NOT add any additional levels.\n",
    "    [Document]\n",
    "    {document}\n",
    "    Please ONLY return the relevant or modified topics at the top level in the hierarchy.\n",
    "    [Your response]\n",
    "    \"\"\"\n",
    "    return query_template.format(document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d543f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qry2(document: str,topic: str) -> str:\n",
    "    query_template = f\"\"\"\n",
    "    You will receive a branch from a topic hierarchy along with some documents assigned to the top-level topic of that branch. Your\n",
    "    task is to identify generalizable second-level topics that can act as subtopics to the top-level topic in the provided branch. Add\n",
    "    your topic(s) if they are missing from the provided branch. Otherwise, return the existing relevant or duplicate topics.\n",
    "    [Example] (Return \"[2] Infrastructure\" (new) and \"[2] Social Event\" (existing) as the subtopics of \"[1] Estonian local news\" (provided).)\n",
    "    Topic branch:\n",
    "    [1] Estonian local news\n",
    "    [2] Social Event\n",
    "    [2] Education\n",
    "    Document 1:\n",
    "    Praegu on juba vundament valmis. \n",
    "    Kiriku plaan on konsistooriumi poolt kinnitatud. \n",
    "    Kogudus on juba kaunis rohkesti ehitusmaterjali kokku vedanud, teliskiva, laudu, palke 250.000 mk. eest. \n",
    "    Siiamaalne ehitus on juba 11/»l 1 /» milj. mk. maksnud. \n",
    "    Sel suvel loodab kogudus ehitust jätkata, ehk ta küll ühe kolmandiku võrra väiksemaks on jäänud selle tõttu, et piiri tõmbamise läbi suur osa maad on Lätimaale jäänud. \n",
    "    Document 2: \n",
    "    Esimese üritusena pidustuste sarjas oli mälestusrännak V.Maarja kalmistule esimese ärijuhi G. Nosenbergi kalmukünkale,\n",
    "    Document 3:\n",
    "    alalisele tänavavalgustusele pandi alus alles 1793. aastal, mil 3. juunil nõudis Tartu politseiülem linnanõukogult, et asehaldurkonna valitsuse määruse kohaselt celseisvast sügisest alates valgustataks linna ja eeslinna laternatega.\n",
    "    Your response:\n",
    "    [1] Estonian local news\n",
    "    [2] Infrastructure (Document: 1, 3): Mentions building of a church and street lighting.\n",
    "    [2] Social Event (Document: 2): Mentions tax policies on imports or exports of goods.\n",
    "    [Instructions]\n",
    "    Step 1: Determine PRIMARY and GENERALIZABLE topics mentioned in the documents.\n",
    "    - The topics must be generalizable among the provided documents.\n",
    "    - Each topic must not be too specific so that it can accommodate future subtopics.\n",
    "    - Each topic must reflect a SINGLE topic instead of a combination of topics.\n",
    "    - Each top-level topic must have a level number and a short label. Second-level topics should also include the original documents\n",
    "    associated with these topics (separated by commas) as well as a short description of the topic.\n",
    "    - The number of topics proposed cannot exceed the number of documents provided.\n",
    "    Step 2: Perform ONE of the following operations:\n",
    "    1. If the provided top-level topic is specific enough, DO NOT add any subtopics. Return the provided top-level topic.\n",
    "    2. If your topic is duplicate or relevant to the provided topics, DO NOT add any subtopics. Return the existing relevant topic.\n",
    "    3. If your topic is relevant to and more specific than the provided top-level topic, add your topic as a second-level topic. DO\n",
    "    NOT add to the first or third level of the hierarchy.\n",
    "    [Topic branch]\n",
    "    {topic}\n",
    "    [Documents]\n",
    "    {document}\n",
    "    DO NOT add first- or third-level topics.\n",
    "    [Your response]\n",
    "    \"\"\"\n",
    "    return query_template.format(document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6603cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qry3( topic: list) -> str:\n",
    "    query_template = f\"\"\"\n",
    "    You will receive a list of topics that belong to the same level of a topic hierarchy. Your task is to merge topics that are paraphrases\n",
    "    or near duplicates of one another. Return \"None\" if no modification is needed.\n",
    "    [Examples]\n",
    "    Example 1: Merging topics (\"[1] Employer Taxes\" and \"[1] Employment Tax Reporting\" into \"[1] Employment Taxes\")\n",
    "    Topic List:\n",
    "    [1] Employer Taxes: Mentions taxation policy for employer\n",
    "    [1] Employment Tax Reporting: Mentions reporting requirements for employer\n",
    "    [1] Immigration: Mentions policies and laws on the immigration process\n",
    "    [1] Voting: Mentions rules and regulation for the voting process\n",
    "    Your response:\n",
    "    [1] Employment Taxes: Mentions taxation report and requirement for employer ([1] Employer Taxes, [1] Employment Tax\n",
    "    Reporting)\n",
    "    Example 2: Merging topics ([2] Digital Literacy and [2] Telecommunications into [2] Technology)\n",
    "    [2] Mathematics: Discuss mathematical concepts, figures and breakthroughs.\n",
    "    [2] Digital Literacy: Discuss the ability to use technology to find, evaluate, create, and communicate information.\n",
    "    [2] Telecommunications: Mentions policies and regulations related to the telecommunications industry, including wireless\n",
    "    service providers and consumer rights.\n",
    "    Your response\n",
    "    [2] Technology: Discuss technology and its impact on society. ([2] Digital Literacy, [2] Telecommunications)\n",
    "    [Rules]\n",
    "    - Each line represents a topic, with a level indicator and a topic label.\n",
    "    - Perform the following operations as many times as needed:\n",
    "    - Merge relevant topics into a single topic.\n",
    "    - Do nothing and return \"None\" if no modification is needed.\n",
    "    - When merging, the output format should contain a level indicator, the updated label and description, followed by the original\n",
    "    topics.\n",
    "    [Topic List]\n",
    "    {topic}\n",
    "    Output the modification or \"None\" where appropriate. Do not output anything else.\n",
    "    [Your response]\n",
    "    \"\"\"\n",
    "    return query_template.format(Topics=topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8cdfc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qry4(topic_hierarchy: list, document:str) -> str:\n",
    "    query_template = f\"\"\"\n",
    "    You will receive a document and a topic hierarchy. Assign the document to the most relevant topics the hierarchy. Then, output\n",
    "    the topic labels, assignment reasoning and supporting quotes from the document. DO NOT make up new topics or quotes.\n",
    "    Here is the topic hierarchy:\n",
    "    {topic_hierarchy}\n",
    "    [Examples]\n",
    "    Example 1: Adding \"[1] Estonian local news\"\n",
    "    Document:\n",
    "    Osaühisus „Mootor“ teatas teedeministeeriumile, et täistuisanud teede tõttu on katkestatud ühendus järgmiste liinide vahel:\\n\\n- Tallinn—Märjamaa\\n- Tallinn—Loksa—Viinistu\\n- Tallinn—Tsitri—Leesi\\n\\nSõidugraafikute täitmine oli seetõttu ajutiselt wõimatu\n",
    "    Your response:\n",
    "    [1] Estonian local news: Mentions local transportation disruptions due to weather conditions.\n",
    "    Example 2: Assign \"[2] Social event\" to the document\n",
    "    Document : \n",
    "    Esimese üritusena pidustuste sarjas oli mälestusrännak V.Maarja kalmistule esimese ärijuhi G. Nosenbergi kalmukünkale,\n",
    "    Your response:\n",
    "    [1] Estonian local news\n",
    "    [2] Social event: Mentions a memorial event at a cemetery.\n",
    "    [Instructions]\n",
    "    1. Topic labels must be present in the provided topic hierarchy. You MUST NOT make up new topics.\n",
    "    2. The quote must be taken from the document. You MUST NOT make up quotes.\n",
    "    3. If the assigned topic is not on the top level, you must also output the path from the top-level topic to the assigned topic.\n",
    "    [Document]\n",
    "    {document}\n",
    "    Double check that your assignment exists in the hierarchy!\n",
    "    [Your response]\n",
    "    \"\"\"\n",
    "    return query_template.format(Topics=topic_hierarchy, document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d64b7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for document 128 successfully written.\n",
      "Response for document 129 successfully written.\n",
      "Response for document 130 successfully written.\n",
      "Response for document 131 successfully written.\n",
      "Response for document 132 successfully written.\n",
      "Response for document 133 successfully written.\n",
      "Response for document 134 successfully written.\n",
      "Response for document 135 successfully written.\n",
      "Response for document 136 successfully written.\n",
      "Response for document 137 successfully written.\n",
      "Response for document 138 successfully written.\n",
      "Response for document 139 successfully written.\n",
      "Response for document 140 successfully written.\n",
      "Response for document 141 successfully written.\n",
      "Response for document 142 successfully written.\n",
      "Response for document 143 successfully written.\n",
      "Response for document 144 successfully written.\n",
      "Response for document 145 successfully written.\n",
      "Response for document 146 successfully written.\n",
      "Response for document 147 successfully written.\n",
      "All responses have been successfully written to a JSON Lines file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEM\")\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "scanned_docs= []\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/text_and_label.jsonl') as f:\n",
    "    documents = json.load(f)\n",
    "with open ('../../src/datasets/silver/scanned/full_scope_data/responses.jsonl','r', encoding='utf-8') as g:\n",
    "    for line in g:\n",
    "        scanned_docs.append(json.loads(line.strip()))\n",
    "scanned_ids = {doc['id'] for doc in scanned_docs}\n",
    "\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/responses.jsonl', 'a') as outfile:\n",
    "    nbr_of_files = 0\n",
    "    for i, document in enumerate(documents):\n",
    "        #if not document['kp']:\n",
    "        #    continue\n",
    "        if document['id'] in scanned_ids:\n",
    "            continue\n",
    "        nbr_of_files += 1\n",
    "        if nbr_of_files > 20:\n",
    "            break\n",
    "        \n",
    "\n",
    "\n",
    "        question_txt = qry1(document['modernized_text'])\n",
    "\n",
    "        data = {\n",
    "            \"contents\": [\n",
    "                {\n",
    "                    \"parts\": [\n",
    "                        {\n",
    "                            \"text\": question_txt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            extracted_data = {\n",
    "                \"qry_id\": 1,\n",
    "                \"id\": document.get(\"id\", \"\"),\n",
    "                \"content\": response_data.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\"),\n",
    "                \"avgLogprobs\": response_data.get(\"candidates\", [{}])[0].get(\"avgLogprobs\", None),\n",
    "                \"modelVersion\": response_data.get(\"modelVersion\", \"\")\n",
    "            }\n",
    "\n",
    "            # Write extracted data as a new line in the output file\n",
    "            outfile.write(json.dumps(extracted_data) + '\\n')\n",
    "            print(f\"Response for document {i + 1} successfully written.\")\n",
    "        else:\n",
    "            print(f\"Error for document {i + 1}: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "\n",
    "print(\"All responses have been successfully written to a JSON Lines file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92d7ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for document 8 successfully written.\n",
      "Response for document 9 successfully written.\n",
      "Response for document 10 successfully written.\n",
      "Response for document 12 successfully written.\n",
      "Response for document 16 successfully written.\n",
      "Response for document 18 successfully written.\n",
      "Response for document 21 successfully written.\n",
      "Response for document 22 successfully written.\n",
      "Response for document 23 successfully written.\n",
      "Response for document 26 successfully written.\n",
      "Response for document 28 successfully written.\n",
      "Response for document 30 successfully written.\n",
      "Response for document 33 successfully written.\n",
      "Response for document 34 successfully written.\n",
      "Response for document 38 successfully written.\n",
      "Response for document 39 successfully written.\n",
      "Error for document 40: 429, {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\",\n",
      "    \"details\": [\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.QuotaFailure\",\n",
      "        \"violations\": [\n",
      "          {\n",
      "            \"quotaMetric\": \"generativelanguage.googleapis.com/generate_content_free_tier_requests\",\n",
      "            \"quotaId\": \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\",\n",
      "            \"quotaDimensions\": {\n",
      "              \"location\": \"global\",\n",
      "              \"model\": \"gemini-2.0-flash\"\n",
      "            },\n",
      "            \"quotaValue\": \"15\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.Help\",\n",
      "        \"links\": [\n",
      "          {\n",
      "            \"description\": \"Learn more about Gemini API quotas\",\n",
      "            \"url\": \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"@type\": \"type.googleapis.com/google.rpc.RetryInfo\",\n",
      "        \"retryDelay\": \"29s\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "All responses have been successfully written to a JSON Lines file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input = []\n",
    "documents = []\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/only_topic_1.jsonl') as f:\n",
    "    for line in f:\n",
    "        documents.append(json.loads(line.strip()))\n",
    "\n",
    "\n",
    "scanned_docs= []\n",
    "\n",
    "with open ('../../src/datasets/silver/scanned/full_scope_data/responses.jsonl','r', encoding='utf-8') as g:\n",
    "    for line in g:\n",
    "        scanned_docs.append(json.loads(line.strip()))\n",
    "scanned_ids = {doc['id'] for doc in scanned_docs if doc['qry_id'] == 2}\n",
    "\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/responses.jsonl', 'a') as outfile:\n",
    "    nbr_of_files = 0\n",
    "    for i, document in enumerate(documents):\n",
    "        if document['id'] in scanned_ids:\n",
    "            continue\n",
    "        nbr_of_files += 1\n",
    "        if nbr_of_files > 20:\n",
    "            break\n",
    "        #print(document)\n",
    "        #print(document['modernized_text'],document['topic_lvl1'])\n",
    "\n",
    "        question_txt = qry2(document['modernized_text'],document['topic_lvl1'])\n",
    "        #break\n",
    "\n",
    "        data = {\n",
    "            \"contents\": [\n",
    "                {\n",
    "                    \"parts\": [\n",
    "                        {\n",
    "                            \"text\": question_txt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            extracted_data = {\n",
    "                \"qry_id\": 2,\n",
    "                \"id\": document.get(\"id\", \"\"),\n",
    "                \"content\": response_data.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\"),\n",
    "                \"avgLogprobs\": response_data.get(\"candidates\", [{}])[0].get(\"avgLogprobs\", None),\n",
    "                \"modelVersion\": response_data.get(\"modelVersion\", \"\")\n",
    "            }\n",
    "\n",
    "            # Write extracted data as a new line in the output file\n",
    "            outfile.write(json.dumps(extracted_data) + '\\n')\n",
    "            print(f\"Response for document {i + 1} successfully written.\")\n",
    "        else:\n",
    "            print(f\"Error for document {i + 1}: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "\n",
    "print(\"All responses have been successfully written to a JSON Lines file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4bb0f560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for document 37 successfully written.\n"
     ]
    }
   ],
   "source": [
    "with open('../../src/datasets/silver/scanned/full_scope_data/topic_refin.jsonl', 'a') as outfile:\n",
    "    \n",
    "    \n",
    "    #list_of_topics = ['Social Event', 'Student Affairs', 'Scouting', 'Economy', 'Land Disputes', 'Newspaper Contact Information', 'Politics', 'Business', 'Infrastructure', 'Announcements', 'Religious Services', 'Crime', 'Education']\n",
    "    list_of_topics = ['Military', 'Media', 'Crime', 'Political conflict', 'Politics', 'Religion', 'Political Affairs', 'Film review', 'Business', 'Education', 'Entertainment', 'Infrastructure', 'Land reform']\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-lite:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "\n",
    "    question_txt = qry3(list_of_topics)\n",
    "        #break\n",
    "\n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\n",
    "                        \"text\": question_txt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        extracted_data = {\n",
    "            \"qry_id\": 2,\n",
    "            \"id\": document.get(\"id\", \"\"),\n",
    "            \"content\": response_data.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\"),\n",
    "            \"avgLogprobs\": response_data.get(\"candidates\", [{}])[0].get(\"avgLogprobs\", None),\n",
    "            \"modelVersion\": response_data.get(\"modelVersion\", \"\")\n",
    "        }\n",
    "        # Write extracted data as a new line in the output file\n",
    "        outfile.write(json.dumps(extracted_data) + '\\n')\n",
    "        print(f\"Response for document {i + 1} successfully written.\")\n",
    "    else:\n",
    "        print(f\"Error for document {i + 1}: {response.status_code}, {response.text}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbb7290e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for document 3044 successfully written.\n",
      "Response for document 3046 successfully written.\n",
      "Response for document 3050 successfully written.\n",
      "Response for document 3051 successfully written.\n",
      "Response for document 3053 successfully written.\n",
      "Response for document 3054 successfully written.\n",
      "All responses have been successfully written to a JSON Lines file.\n"
     ]
    }
   ],
   "source": [
    "Hierarchy = [['[1] Estonian local news','[2] Social Event', '[2] Economy', '[2] Newspaper Contact Information', '[2] Infrastructure', '[2] Land Disputes', '[2] Education', '[2] Business', '[2] Crime', '[2] Student Affairs', '[2] Politics', '[2] Announcements', '[2] Religious Services', '[2] Scouting']\n",
    "             ,['[1] World news', '[2] Military', '[2] Media', '[2] Crime', '[2] Political conflict', '[2] Politics', '[2] Religion', '[2] Political Affairs', '[2] Film review', '[2] Business', '[2] Education', '[2] Entertainment', '[2] Infrastructure', '[2] Land reform']]\n",
    "\n",
    "input = []\n",
    "documents = []\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key={GEMINI_API_KEY}\"\n",
    "\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/world_news.jsonl') as f:\n",
    "    for line in f:\n",
    "        documents.append(json.loads(line.strip()))\n",
    "\n",
    "\n",
    "scanned_docs= []\n",
    "\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/text_and_label.jsonl') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "with open ('../../src/datasets/silver/scanned/full_scope_data/responses.jsonl','r', encoding='utf-8') as g:\n",
    "    for line in g:\n",
    "        scanned_docs.append(json.loads(line.strip()))\n",
    "scanned_ids = {doc['id'] for doc in scanned_docs if doc['qry_id'] in (1,2,4)}\n",
    "\n",
    "with open('../../src/datasets/silver/scanned/full_scope_data/responses.jsonl', 'a') as outfile:\n",
    "    nbr_of_files = 0\n",
    "    for i, document in enumerate(documents):\n",
    "        if not document['kp']:\n",
    "            continue\n",
    "        if document['id'] in scanned_ids:\n",
    "            continue\n",
    "        nbr_of_files += 1\n",
    "        if nbr_of_files > 20:\n",
    "            break\n",
    "        #print(document)\n",
    "        #print(document['modernized_text'],document['topic_lvl1'])\n",
    "\n",
    "        question_txt = qry4(Hierarchy,document['modernized_text'])\n",
    "        #break\n",
    "\n",
    "        data = {\n",
    "            \"contents\": [\n",
    "                {\n",
    "                    \"parts\": [\n",
    "                        {\n",
    "                            \"text\": question_txt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            extracted_data = {\n",
    "                \"qry_id\": 4,\n",
    "                \"id\": document.get(\"id\", \"\"),\n",
    "                \"content\": response_data.get(\"candidates\", [{}])[0].get(\"content\", {}).get(\"parts\", [{}])[0].get(\"text\", \"\"),\n",
    "                \"avgLogprobs\": response_data.get(\"candidates\", [{}])[0].get(\"avgLogprobs\", None),\n",
    "                \"modelVersion\": response_data.get(\"modelVersion\", \"\")\n",
    "            }\n",
    "\n",
    "            # Write extracted data as a new line in the output file\n",
    "            outfile.write(json.dumps(extracted_data) + '\\n')\n",
    "            print(f\"Response for document {i + 1} successfully written.\")\n",
    "        else:\n",
    "            print(f\"Error for document {i + 1}: {response.status_code}, {response.text}\")\n",
    "            break\n",
    "\n",
    "print(\"All responses have been successfully written to a JSON Lines file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
